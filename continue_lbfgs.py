#!/usr/bin/env python3
"""
NACA 0012 Flutter PINN - LBFGS ì´ì–´ì„œ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
Adam í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ì—ì„œ LBFGSë§Œ ì¶”ê°€ í•™ìŠµ
"""

import torch
import torch.optim as optim
import os
from pathlib import Path
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from config import *
from pinn_model import create_pinn_model
from boundary_conditions import create_boundary_manager
from structure_dynamics import create_structure_system
from data_io import DataProcessor
from utils import *
from main import PINNTrainer

class LBFGSContinueTrainer(PINNTrainer):
    """LBFGS ì´ì–´ì„œ í•™ìŠµì„ ìœ„í•œ íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, phys_params, domain_params, pinn_config, 
                 training_config, file_config, coord_sys: str = "lab"):
        super().__init__(phys_params, domain_params, pinn_config, 
                        training_config, file_config, coord_sys)
        
    def load_best_model(self):
        """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ"""
        results_dir = Path(r"C:\Users\Master\Desktop\NACA0012_Flutter_PINN\results")
        
        # ê°€ëŠ¥í•œ ëª¨ë¸ íŒŒì¼ë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
        model_candidates = [
            results_dir / "best_model.pt",
            results_dir / "checkpoint_epoch_4999.pt",
            results_dir / "checkpoint_epoch_4899.pt",
        ]
        
        model_path = None
        for candidate in model_candidates:
            if candidate.exists():
                model_path = candidate
                break
        
        if model_path is None:
            raise FileNotFoundError("âŒ ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        
        print(f"ğŸ“ ëª¨ë¸ ë¡œë“œ: {model_path}")
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        
        start_epoch = checkpoint.get('epoch', 0)
        best_loss = checkpoint.get('loss', float('inf'))
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"   ì‹œì‘ ì—í¬í¬: {start_epoch}")
        print(f"   ìµœê³  ì†ì‹¤: {best_loss:.6f}")
        
        return start_epoch, best_loss
    
    def lbfgs_only_training(self, processed_data: Dict):
        """LBFGSë§Œ í•™ìŠµ"""
        from loguru import logger
        
        print("ğŸ”§ LBFGS ì´ì–´ì„œ í•™ìŠµ ì‹œì‘")
        print("="*50)
        
        # ëª¨ë¸ ë¡œë“œ
        start_epoch, best_loss = self.load_best_model()
        
        # LBFGS ìµœì í™”ê¸° ìƒì„±
        logger.info(f"LBFGS ìµœì í™” ì‹œì‘ ({self.training_config.lbfgs_epochs} epochs)")
        
        try:
            optimizer_lbfgs = optim.LBFGS(
                self.model.parameters(),
                lr=0.1,
                max_iter=20,
                max_eval=None,
                tolerance_grad=1e-7,
                tolerance_change=1e-9
            )
            
            # LBFGS í•™ìŠµ ì‹¤í–‰
            self._train_lbfgs_phase(optimizer_lbfgs, self.training_config.lbfgs_epochs, 
                                   processed_data, start_epoch)
            
            logger.info("ğŸ‰ LBFGS í•™ìŠµ ì™„ë£Œ!")
            
        except RuntimeError as e:
            if "does not require grad" in str(e):
                logger.warning("âš ï¸ LBFGS gradient ì˜¤ë¥˜ ë°œìƒ")
                logger.warning(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")
                logger.info("ğŸ’¡ Adam ëª¨ë¸ì´ ì´ë¯¸ ì¢‹ì€ ì„±ëŠ¥ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”")
            else:
                raise e
    
    def _train_lbfgs_phase(self, optimizer, num_epochs: int, processed_data: Dict, 
                          start_epoch: int):
        """LBFGS í•™ìŠµ í˜ì´ì¦ˆ"""
        from loguru import logger
        
        # ì†ì‹¤ ì¶”ì ê¸°
        loss_tracker = LossTracker()
        
        # ì§„í–‰ë¥  í‘œì‹œ
        progress_bar = tqdm(range(num_epochs), desc="LBFGS í•™ìŠµ")
        
        best_loss = float('inf')
        
        for epoch in progress_bar:
            self.model.train()
            
            # ìƒ˜í”Œ ìƒì„±
            samples = self.generate_training_samples()
            
            # ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ requires_grad ì¬ì„¤ì •
            for key, value in samples.items():
                if isinstance(value, torch.Tensor):
                    value.requires_grad_(True)
                elif isinstance(value, dict):
                    for subkey, subvalue in value.items():
                        if isinstance(subvalue, torch.Tensor):
                            subvalue.requires_grad_(True)
            
            def closure():
                optimizer.zero_grad()
                losses = self.training_step(samples, processed_data, start_epoch + epoch)
                losses['total'].backward()
                return losses['total']
            
            # LBFGS ìŠ¤í…
            optimizer.step(closure)
            
            # ì†ì‹¤ ê³„ì‚° (ê¸°ë¡ìš©)
            with torch.no_grad():
                losses = self.training_step(samples, processed_data, start_epoch + epoch)
            
            # ì†ì‹¤ ê¸°ë¡
            loss_dict = {k: v.item() if isinstance(v, torch.Tensor) else v 
                        for k, v in losses.items()}
            loss_tracker.update(loss_dict, start_epoch + epoch)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress_bar.set_postfix({
                'Total': f"{losses['total'].item():.2e}",
                'PDE': f"{losses['pde'].item():.2e}",
                'BC': f"{losses['bc'].item():.2e}",
                'FSI': f"{losses['fsi'].item():.2e}" if 'fsi' in losses else "0.0e+00"
            })
            
            # ìµœê³  ëª¨ë¸ ì €ì¥
            current_loss = losses['total'].item()
            if current_loss < best_loss:
                best_loss = current_loss
                self.save_checkpoint(start_epoch + epoch, current_loss, "lbfgs_best_model.pt")
            
            # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸
            if (epoch + 1) % 100 == 0:
                checkpoint_name = f"lbfgs_checkpoint_epoch_{start_epoch + epoch}.pt"
                self.save_checkpoint(start_epoch + epoch, current_loss, checkpoint_name)
        
        # ì†ì‹¤ ê³¡ì„  ì €ì¥
        loss_tracker.save_history(os.path.join(self.file_config.output_dir, "lbfgs_loss_history.json"))
        
        print(f"\nâœ… LBFGS í•™ìŠµ ì™„ë£Œ!")
        print(f"   ìµœì¢… ì†ì‹¤: {best_loss:.6f}")
        print(f"   ìµœê³  ëª¨ë¸: lbfgs_best_model.pt")
    
    def save_checkpoint(self, epoch: int, loss: float, filename: str):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        save_dict = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'loss': loss,
            'model_config': self.pinn_config
        }
        
        save_path = os.path.join(self.file_config.output_dir, filename)
        torch.save(save_dict, save_path)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ LBFGS ì´ì–´ì„œ í•™ìŠµ ì‹œì‘")
    print("="*50)
    
    # ì„¤ì • ë¡œë“œ
    phys_params = PhysicalParameters()
    domain_params = DomainParameters()
    pinn_config = PINNConfig()
    training_config = TrainingConfig()
    file_config = FileConfig()
    
    # ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”
    initialize_utils("INFO", file_config.output_dir)
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = LBFGSContinueTrainer(
        phys_params, domain_params, pinn_config, 
        training_config, file_config, "lab"
    )
    
    try:
        # ë°ì´í„° ì¤€ë¹„
        processed_data = trainer.prepare_data()
        
        # LBFGSë§Œ í•™ìŠµ
        trainer.lbfgs_only_training(processed_data)
        
        print("\nğŸ‰ LBFGS ì´ì–´ì„œ í•™ìŠµ ì™„ë£Œ!")
        print("ğŸ“ ê²°ê³¼ë¬¼:")
        print("   - lbfgs_best_model.pt: ìµœê³  ì„±ëŠ¥ ëª¨ë¸")
        print("   - lbfgs_loss_history.json: ì†ì‹¤ ì´ë ¥")
        print("   - lbfgs_checkpoint_epoch_*.pt: ì²´í¬í¬ì¸íŠ¸ë“¤")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()